--- 
title: "Organised, transparent and reproducible science using R, git, and remake"
author: "D Barneche"
site: bookdown::bookdown_site
output:
    bookdown::pdf_book:
        includes:
            in_header: header.tex
    bookdown::gitbook:
        config:
            sharing: null
        css: 'style.css'
        includes:
            in_header: _toggle.html
        keep_md: TRUE
linkcolor: blue
documentclass: book
link-citations: yes
description: "Organised, transparent and reproducible science using R, git, and remake"
---

# How to organise your project directories

```{r, child = "_setup.Rmd", include = F, purl = F, cache = F}
```

The scientific process is naturally incremental, and many projects
start life as random notes, some code, then a manuscript, and
eventually everything is a bit mixed together.

<!-- more -->

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Managing your projects in a reproducible fashion doesn&#39;t just make your science reproducible, it makes your life easier.</p>&mdash; Vince Buffalo (@vsbuffalo) <a href="https://twitter.com/vsbuffalo/status/323638476153167872?ref_src=twsrc%5Etfw">April 15, 2013</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

## Directory layout

### The general disaster

Many people tend to organise their projects like this:

![](pics/bad_layout.png)

There are many reasons why we should *ALWAYS* avoid this:

1. It is really hard to tell what version of your data is
the original and what is the modified;
2. It gets really messy because it mixes files with various
extensions together;
3. It probably takes you a lot of time to actually find
things, and relate the correct figures to the exact code
that has been used to generate it;
4. You may face professional embarrassment when sharing your
project directory with a colleague or your supervisor.

### A niceR solution

A good project layout helps ensure the

* Integrity of data
* Portability of the project
* Easier to pick the project back up after a break

There is no one way to lay a project out. We have
different approaches for different projects, reflecting the history of
the project, who else is collaborating on that project.

Here are a couple of different ideas for laying a project out.  This
is the basic structure that I tend to use:

```
proj/
|-- R/
|-- data/
|-- output/
|-- |-- data/
|-- |-- figures/
|-- doc/
```

* The `R` directory contains various files with function definitions
  (but *only* function definitions - no code that actually runs).

* The `data` directory contains data used in the analysis.  This is
  treated as *read only*; in particular the R files are never allowed
  to write to the files in here.  Depending on the project, these
  might be csv files, a database, and the directory itself may have
  subdirectories.

* The `output/data` directory contains simulation output, processed
  datasets, logs, or other processed things. The `output/figures`
  directory contains the output figures generated by your code.
  Altogether the `output` directory *only contains generated files*;
  that is, I should always be able to delete the contents and regenerate them.

* The `doc` directory contains the paper. I work in Markdown which is
  nice because it can pick up figures directly made by R. Markdown
  is starting to get traction among biologists. With Word you'll have
  to paste them in yourself as the figures update.

In this set up, I usually have the R script files that *do* things in
the project root:

```
proj/
|-- R/
|-- data/
|-- output/
|-- |-- data/
|-- |-- figures/
|-- doc/
|-- analysis.R
```

For very simple projects, you might drop the R directory, perhaps
replacing it with a single file `analysis-functions.R` which you
`source` within the .R files that depend on the outputs.

The top of the analysis file usually looks something like

```r
library(some_package)
library(some_other_package)
source("R/functions.R")
source("R/utilities.R")
```

...followed by the code that loads the data, cleans it up, runs the
analysis and generates the figures.

Other people have other ideas

* [Carl Boettiger](http://www.carlboettiger.info/2012/05/06/research-workflow.html)
  is an open science advocate who has described his
  [layout in detail](http://www.carlboettiger.info/2012/05/06/research-workflow.html).
  This layout uses R packages for most of the code organisation, and
  would be a nice approach for large projects.

* [This article](http://www.ploscompbiol.org/article/info%3Adoi%2F10.1371%2Fjournal.pcbi.1000424)
  in [PLOS Computational Biology](http://www.ploscompbiol.org/)
  describes a general framework.

### Treat data as read only

This is probably the most important goal of setting up a
project. Data are typically time consuming and/or expensive to
collect. Working with them interactively (e.g., in Excel) where they
can be modified means you are never sure of where the data came from,
or how they have been modified. We suggest to put your data
into the `data` directory and treat it as *read only*. Within your
scripts you might generate derived data sets either temporarily (in an
R session only) or semi-permanently (as an file in `output/data`), but
the original data is always left in an untouched state.

### Treat generated output as disposable

In this approach, files in directory `output/` are all generated
by the scripts.  A nice thing about this approach is that if
the file names of generated files change (e.g, changing from
`phylogeny.pdf` to `mammal-phylogeny.pdf`) files with the old names
may still stick around, but because they're in this directory you know
you can always delete them. Before submitting a paper, I will go
through and delete all the generated files and rerun the analysis to
make sure that I can create all the analyses and figures from the
data.

### Separate function definition and application

When your project is new and shiny, the script file usually contains
many lines of directly executed code. As it matures, reusable
chunks get pulled into their own functions. The actual analysis
scripts then become relatively short, and use the functions defined in
scripts in `R`. Those scripts do nothing but define functions so that
they can always be `source()`'d by the analysis scripts.

## Setting up a project in RStudio

This gets rid of the #1 problem with most people's projects face;
where do you find the data. Two solutions people generally come up
with are:

1. Hard code the full file name for each file you load (e.g.,
`/Users/barneche/phd/ctotpaper/data/some_data.csv`)
2. Set the working directory at the beginning of your script file
`/Users/barneche/phd/ctotpaper/` then doing `read.csv("data/some_data.csv")`

The second of these is probably preferable to the first, because the
"special case" part is restricted to just one line in your file.
However, the project is still now quite fragile, because moving it
from one place to another, you must change this file. Some examples
of when you might do this:

* Archiving a project (moving it from a "current projects" directory
  to a new projects directory)
* Giving the code to somebody else (your lab mate, collaborator, supervisor)
* Uploading the code with your manuscript submission for review, or to
  [Dryad](http://datadryad.org/) after acceptance.
* New computer and new directory layout (especially changing
  platforms, or if your previous mess got too bad and you wanted to
  clean up).
* Any number of new reasons

The second case hints at a solution too; if we can start R in a
particular directory then we can just use paths *relative to the
project root* and have everything work nicely.

To create a project in R studio:

  - "File": "New Project..."
  - choose "New Directory (start a project in a brand new working directory)".
  - Under "Project Type", choose "New Project".
  - In the "Directory name" type the name for the project.  This might
    be `chapter_n` for a thesis, or something more descriptive like
    `fish_behaviour`.
  - In the "Create project as a subdirectory of" field select (type or
    browse) for the parent directory of the project. By default this
    is probably your home directory, but you might prefer your
    Documents folder.

# Version control

## Why use version control?

There are many reasons to use version control, and some of these may only become apparent after you have incorporated it into your workflow (it's a bit like "why use R" or "why document your code").  However, we can immediately  identify a set of advantages that are very common.

Most of these come from having **a fossil record that captures the evolution of your project** (including code, data, documentation, analyses, figures, talks, etc).

This fossil record, or project history, is a series of revisions that connect to each other between the present and the start of the project.  At any time you can go back to previous versions, see what you did, and run the code as though you have stepped back in time.

Having a good fossil history has numerous possible uses :

1. **You noticed that your code is doing odd things now and didn't used to.** Look at and run a version from the last known good code and try to work out what changed (after this, you should write a unit test!).

2. **You deleted some code and want to get it back.**  This has a less obvious, but much more common (and perhaps more important) advantage; you will be more likely to delete old code rather than commenting it out, leaving you with shorter, more readable scripts.

3. **You want to show your supervisor what you did last week.**

4. Inversely, on a collaborative project, **see what your collaborators wrote last week.**

5. You reformatted everything from numbered citation styles to author-year after being rejected from journal A and sending your paper to journal B.  Journal B didn't want the paper anyway, so you can **get the previous version back.**

6. **You want to experiment** and try something that might break huge pieces of your project, and know that you can back out if things go awry.

7. Similarly, **you want to try a couple of different strategies for solving a problem** and review which one you like best (or show them to someone else).

8. Gives you **an audit-able project history**; you know when you did what you did.

The other great reason for using version control is that it allows for effective and transparent collaboration among small or large groups of scientists.

### You are already using version control

Whether you recognise it or not, you are most likely already using some form of version control to achieve some of the advantages outlined above. This might include

* Commented out bits of code / text
* Files with numbers afterwards (`thesis_v1.doc`, `thesis_v2.doc`, `thesis_final.doc`, `thesis_final2.doc`, etc) (like in this [Phd Comic](http://www.phdcomics.com/comics/archive.php?comicid=1531))
* Every so often you zip up the whole project directory and save it with the date appended to the filename.

Most ecologists we know have adopted at least one of these techniques for doing version control.

In addition, you'll often see people suggesting putting headers like this in your code file:

```
  ## My file (c) John Snow
  ## Created: 2018/10/04
  ## Modified: 2019/04/04
```

Sometimes you'll even see change logs embedded in these.

The problem with this is that it's repetitive and boring, it's difficult to extract the information easily (e.g., get me all the files **I** modified in the last month), there is no checking on the contents of the fields (dates in the future, forgetting to update dates, inconsistent names, email addresses).  The *point* of these headers is nice --- keep track of who did what and when, but this is far easier to achieve under a good version control system.

Another thing you'll find in many people's code is large chunks of old code, commented-out because you think you might need it it again one day.

### Version control is not a back up

It appears that this is like a brilliant backup system, but you need a
backup too.  Backing up is a complementary set of functions that
overlap only in that there is usually some history going back.

* Back up but not git: corruption of repository, generated files that are not part of a repository but time consuming, installed software and other system issues.  It is possible (but often hard) to break your git repository; you might reclone from somewhere or you might grab the last copy of a backup.  Backup systems usually have larger capacity than online version control systems.

* Git but not backup: semantics around files, parallel branched versions of files, check out by either checkpoint or time (not just last time, etc).

A good version control system does not substitute for a good backup system. *Backing up* offers a complementary set of functions that only partially overlap with those offered by version control. In general, you need both.

I have all my projects under version control, and my whole documents directory under backup.  If my computer fails, I immediately copy my documents directory from the backup to a new computer.  I only need to get the last version though.  On the other hand, at any time I can easily look back through the history of any project and see the work.  For some projects, the last modification was months ago, while most backup system will be seriously thinning by this point (moving to monthly snapshots at best, and you probably have to pay for that).

Other systems, like Dropbox, are more like backups, as they do not store your project history.

## Basic git configuration

When we use git on a new computer for the first time, we need to configure a few things. Below are a few examples of configurations we will set as we get started with git:

* our name and email address,

* what our preferred text editor is,

* and that we want to use these settings globally (i.e. for every project).

On a command line, git commands are written as `git verb options`, where `verb` is what we actually want to do and `options` is additional optional information which may be needed for the `verb`. So here is how John Snow sets up his new laptop:

    $ git config --global user.name "John Snow"
    
    $ git config --global user.email "j.snow@email.com"

    $ git config --global color.ui "auto"

Please use your own name and email address instead of John Snow's. If it returns no errors, then verify that these settings were saved into your configuration file (`.gitconfig`) by running:

    $ git config --list

    $ git config user.name

This user name and email will be associated with your subsequent git activity, which means that any changes pushed to any git host server (e.g. [GitHub](http://github.com/), [BitBucket](https://bitbucket.org/), [GitLab](https://about.gitlab.com/)) in a later lesson will include this information.

For these lessons, we will be interacting with GitHub and so the email address used should be the same as the one used when setting up your GitHub account. If you are concerned about privacy, please review [GitHub's instructions for keeping your email address private](https://help.github.com/articles/keeping-your-email-address-private/).

### Keeping your email private

If you elect to use a private email address with GitHub, then use that same email address for the `user.email` value, e.g. `username@users.noreply.github.com` replacing `username` with your GitHub one.

### Line Endings

As with other keys, when you hit Return/Enter on your keyboard, your computer encodes this input as a character. Different operating systems use different character(s) to represent the end of a line. (You may also hear these referred to as newlines or line breaks.) Because git uses these characters to compare files, it may cause unexpected issues when editing a file on different machines. Though it is beyond the scope of this lesson, you can read more about this issue on this [GitHub page](https://help.github.com/articles/dealing-with-line-endings/).

You can change the way git recognises and encodes line endings using the `core.autocrlf` command to `git config`. The following settings are recommended:

On macOS and Linux:

    $ git config --global core.autocrlf input

And on Windows:

    $ git config --global core.autocrlf true

### Configure your text editor

The simple editor `nano` is likely to be the simplest thing to use (at least on a Mac).

    $ git config --global core.editor "nano --tempfile" 

The default is `vi`.  If anyone ends up with a screen does not seem to respond to anything they type, you may have activated vi.  Put your hand up and we'll help you out.

Other options:
* "gedit -w -s" 
* "kate"
* "subl -n -w' for Sublime Text 2.

###  Other editors 

On Windows using Notepad++ in the standard location for a 64-bit machine, you would use:

    $ git config --global core.editor "'C:/Program Files (x86)/Notepad++/notepad++.exe' -multiInst -notabbar -nosession -noPlugin"

(thanks to [StackOverflow](http://stackoverflow.com/questions/1634161/how-do-i-use-notepad-or-other-with-msysgit/2486342#2486342)  for that useful tip)

On Mac, with TextWrangler if you installed TextWrangler's command line tools
then you should have an "edit" command. So you can use the git command:

    $  git config --global core.editor "edit -w"

## Git basics

Essentially, all version control does is store snapshots of your work
in time, and keeps track of the parent-child relationships.

![git history](pics/git-intro-history.png)

You can think of your current set of working files as simply the
child of the last node in this chain (that is, your files are the
children of the most recent set of files known to the version control
system).

`git` provides a large number of tools for manipulating this history.
We'll only touch on a few, but the number that you need to know for
day-to-day use is actually quite small.

First, we're going to need some terminology:

* **Repository**: "Repo" for short; this is a copy of the history of
  your project.  It is **stored in a hidden directory within your
    project**.  People will talk about "cloning a repo" or "adding things
  to a repo"; these all manipulate the history in some way.
* **Working directory**: This is your copy of a project.  It's just a
  directory with files and other directories in it.  The repository is
  contained within a `.git` directory at the root directory of your
  project.

One of the distinguishing and great features about git is that the repo contains the entire history of the project, i.e. if your project moves, the history travels with it. So if you clone your work to a new computer, or a collaborator gets involved (more on how to do that later), they have the full project history available.  This is called [distributed version control](en.wikipedia.org/wiki/ Distributed_revision_control).

## What goes in my repository? 

You should establish a new repo for each project you are working on. Your project folder should contain everything related to a particular project, including inputs (data, images, notes), analysis scripts and outputs (figures, tables.) The content of your project will evolve over time and this will be tracked within the git repo.

But not all of your project folder contents will be stored within the git system. As a general guide, we suggest you make a folder called outputs. This is where you should save figures and other outputs from your analysis scripts. These outputs do not need to be tracked, as they can be reproduced at any time by rerunning the script. Later we'll show you how to `ignore` certain files in git.

## The commit cycle

Your project develops as you do work. During this process you make a series of 
small changes such as

- writing some code 
- importing/entering  new data
- reorganising your files
- making a figure
- writing bits of reports or papers.

The idea with git is that you break up your project activity into a series of small tasks, each corresponding to a 'commit'. So the cycle goes

> Checkout project --> do work --> review changes --> commit

Anecdotal evidence suggests experienced programmers break up their project into lots of small pieces, and have lots of commits in their work cycle, while novices tend to have fewer, larger commits. some of the advantages of small commits are

- helps you to focus on one small piece of a much larger puzzle
- it's easier to recover if something goes wrong
- you have a greater sense of achievement. 

If you're trucking along for hours (or days) at a time without committing anything, chances are you're changing too much.  A good way of thinking about version control is like the ability to press "undo" when writing.  You don't know when you'll need to go back (and most of the time you don't need to).  But when you do, you don't want to have to have to choose between two vastly different copies of a document.  With programming it's even more important; multiple files that depend on each other are changing.
 
You should aim to only commit once a piece of code works, so that you
leave your code in working order:  commits serve as checkpoints where individual files or an entire project can be safely reverted to when necessary.

## Creating a repository

If you want to create a repository from the command line, use the
command

```
git init
```

which will print something like

```
Initialized empty Git repository in /path/to/your/repository/.git/
```

The `.git` directory is a *hidden directory*.  You can view it with `ls -a`, but it will be hidden with just `ls`.  This store some configuration settings, but you'll rarely need to edit them directly.  It also stores all the previous versions of your working directory (but does it in all sorts of clever and efficient ways).

## The add-commit cycle

We will use a few commands.

The first is `git status`.  This tells you the status of all the files in your project that *are not up to date*.  At the moment, it contains:

```
# On branch master
#
# Initial commit
#
# Untracked files:
#   (use "git add <file>..." to include in what will be committed)
#
#   .gitignore
#   script.R
#   vc.Rproj
nothing added to commit but untracked files present (use "git add" to track)
```

The command `git add` indicates which files we want to add:

```
git add script.R
git status
# On branch master
#
# Initial commit
#
# Changes to be committed:
#   (use "git rm --cached <file>..." to unstage)
#
#   new file:   script.R
#
# Untracked files:
#   (use "git add <file>..." to include in what will be committed)
#
#   .gitignore
#   vc.Rproj
```

This tells us all of the things that we are going to commit (`script.R`) and the files that git does not know about (`.gitignore` and `vc.Rproj`).  The command `git commit` does the actual addition.  The `-m` option passes in a message for the commit.

```
git commit -m "Added function that computes standard error of the mean."
```

which prints

```
[master (root-commit) 514f871] Added function that computes standard error of the mean.
 1 file changed, 3 insertions(+)
 create mode 100644 script.R
```

which is essentially the same information that RStudio showed after committing.

We can add the other files:

```
git add .gitignore vc.Rproj
git commit -m "Added RStudio files"
```

which will print 

```
[master 519a8e3] Added RStudio files
 2 files changed, 16 insertions(+)
 create mode 100644 .gitignore
 create mode 100644 vc.Rproj
```

To clarify what is going on, look at this figure

![](pics/git-info.png)


You use `git add` to tell git what content you want it to track (new files, or changes to files that it already knows about) and then `git commit` to add that content to the repository.  (Don't worry about the last section, push yet, but that lets you keep the content of your local repository in sync with a repository on another computer, or on a hosting website like [http://github.com](GitHub).)

To see the history

```
git log
```

which will print something like

```
commit 519a8e3b3c0558faf8b0ad9c6d7d269e72a6571a
Author: Rich FitzJohn <rich.fitzjohn@gmail.com>
Date:   2013-04-17 14:08:09 +1000
 
    Added RStudio files
 
commit 514f871aa41127f94daaeb3360dda6a70ec3fb36
Author: Rich FitzJohn <rich.fitzjohn@gmail.com>
Date:   2013-04-17 11:51:54 +1000
 
    Added function that computes standard error of the mean.
```

### What is going on with those crazy strings of numbers?

You may have noticed the long strings of numbers, such as:

```
commit 519a8e3b3c0558faf8b0ad9c6d7d269e72a6571a
```

These are called "hashes"; think of them as a fingerprint of a file, or of a commit.  Git uses them everywhere, so these get used where you would otherwise use "version1", or "final", etc.

The nice thing about them is that they depend on the entire history of a project, so you know that your history is secure.  For example, I deleted the full stop at the end of the first commit message ([don't ask me how](http://stackoverflow.com/a/2119656)) and reran `git log`

```
commit a0f9f692319eb7103bd0485181b45c3bf229851f
Author: Rich FitzJohn <rich.fitzjohn@gmail.com>
Date:   2013-04-17 14:08:09 +1000

    Added RStudio files

commit 9b5f828a285577d53dc40a28fa3cd7e4cc1a691d
Author: Rich FitzJohn <rich.fitzjohn@gmail.com>
Date:   2013-04-17 11:51:54 +1000

    Added function that computes standard error of the mean
```

You might expect that the hash for the first commit would change, but notice that it is has changed a *lot* for just one character difference.  Also notice that the second commit has a new hash too; this is because one of the "things" in the second commit is a pointer back to the first commit indicating who its parent is.

Confused?  Don't worry.  All you need to know is that the hash identifies your **entire project including its history**, and that if anything changes anything in the project, the hashes will change.  This is great because it allows us to use the big ugly strings of letters and numbers as a shortcut for a very precise set of information.

### What changed?

There are lots of ways of seeing what has changed.  Probably too many, and the options get overwhelming.  Later on, we'll look at a website that makes that a lot easier for previous versions.

Being able to see what has changed is incredibly useful, and once you start thinking with version control you'll constantly look to see what has changed.  The confidence that you can always go back is what makes version control empowering.

Suppose we change the `script.R` file again:

```
# Standard error function
se <- function(x, na.rm=TRUE) {
  n <- if ( na.rm ) length(na.omit(x)) else x
  sqrt(var(x, na.rm=na.rm) / n)
}
```

we'll see that `git status` reports that the file has changed:

```
# On branch master
# Changes not staged for commit:
#   (use "git add <file>..." to update what will be committed)
#   (use "git checkout -- <file>..." to discard changes in working directory)
#
#   modified:   script.R
#
no changes added to commit (use "git add" and/or "git commit -a")
```

The command `git diff` shows the change between the contents of the working directory and the changes that would be commited.  So with nothing to commit, this is the difference between the files in the directory and the last revision.  Running `git diff` reports:

```
diff --git a/script.R b/script.R
index 22431f2..9f9ad79 100644
--- a/script.R
+++ b/script.R
@@ -1,3 +1,5 @@
 # Standard error function
-se <- function(x)
-  sqrt(var(x, na.rm=TRUE) / length(na.omit(x)))
+se <- function(x, na.rm=TRUE) {
+  n <- if ( na.rm ) length(na.omit(x)) else x
+  sqrt(var(x, na.rm=na.rm) / n)
+}
```

if we add the file to "stage" it with:

```
git add script.R
```

and rerun `git diff`, there is no output.  The command `git status` now reports

```
# On branch master
# Changes to be committed:
#   (use "git reset HEAD <file>..." to unstage)
#
#   modified:   script.R
#
```

indicating that `script.R` will be added when we do `git commit`.  You can review what would be commited line-by-line by running

```
git diff --cached
```

which compares the contents of the staged changes with the previous version.

## Looking at the history

Lots of different ways of looking at the history.  A very few useful ones:

* git log --oneline --topo-order --graph --decorate
* git diff --since=1week --until=1day
* git diff --stat --since=1week --until=1day
* git diff -3 # last three commits


# Acknowledgements

Daniel Falster
Rick FitzJohn
This bookdown material was [adapted from the nice R code blog](http://nicercode.github.io/blog/2013-04-05-projects/) and modified by Diego Barneche
http://swcarpentry.github.io/git-novice/02-setup/index.html


















Basically a standard Bookdown template with a few tweaks. New chapters need to be in separate '.Rmd' files, where each file starts with a chapter heading as seen [here](https://bookdown.org/yihui/bookdown/usage.html). In order to use the task and solution blocks in \LaTeX, you must input the order of the files into the `_bookdown.yml` file, and the first file must be called `index.Rmd` e.g.

```
rmd_files:
    html: ['index.Rmd', 'ch1.Rmd']
    latex: ['index.Rmd', 'ch1.Rmd', 'ch_appendix.Rmd']
output_dir: "docs"
```

The `latex:` path above ***must*** have `'ch_appendix.Rmd'` as its last entry. This ensures that the appendix is properly formatted for the solutions to the problems.

There are a couple of useful special blocks. A `task` block, and a `solution` block. These can be used as e.g.

````
```{task}`r ''`
Here is a task written in **markdown**.
```
````

which renders as:

```{task}
Here is a task written in **markdown**.
```

You can include chunks within the `task` chunk, but you need to use double backticks *within* the chunk, and leave carriage returns around the internal chunk e.g.

````

```{task}`r ''`

``{r}
x <- 2 + 2
x
``

```

````

which renders as:

```{task}

``{r}
x <- 2 + 2
x
``

```

Be careful to have suitable carriage returns around e.g. `enumerate` or `itemize` environments inside the chunk also. For example:

````

```{task}`r ''`
Here is a list:
1. item 1
2. item 2
```

```` 

will not render nicely. But

````

```{task}`r ''`
Here is a list:

1. item 1
2. item 2

```

```` 

will:

```{task}
Here is a list:

1. item 1
2. item 2

```

The `solution` chunk works in the same way, and the numbers will follow the previous `task` chunk (so you can set tasks without solutions) e.g.

````

```{task}`r ''`
Add 2 and 2 together
```

```{solution}`r ''`

``{r}
2 + 2
``

```

````

gives:

```{task}
Add 2 and 2 together
```

```{solution}

``{r}
2 + 2
``

```

To compile, run the `_build.sh` script which will compile into multiple formats. 

## Additional extensions

### Different task and solution titles

Task and solution boxes can also be given different names using the `title` option e.g.

````

```{task, title = "Question"}`r ''`
What is the meaning of life, the universe and everything?
```

```{solution, title = "Answer"}`r ''`
Why 42 of course!
```

````

gives:

```{task, title = "Question"}
What is the meaning of life, the universe and everything?
```

```{solution, title = "Answer"}
Why 42 of course!
```

### Tabbed boxed environments

Originally developed to put base R and `tidyverse` solutions side-by-side, using a `multCode = T` option to the solution box. Here the two tabs are separated by four consecutive hashes: `####`, and the `titles` option gives the tab titles (these can be set globally if preferred) e.g.

```{r, include = F}
library(tidyverse)
```

````

```{task}`r ''`
Filter the `iris` data by `Species == "setosa"` and find the mean `Petal.Length`.
```

```{solution, multCode = T, titles = c("Base R", "tidyverse")}`r ''`

``{r}
## base R solution
mean(iris$Petal.Length[
    iris$Species == "setosa"])
``

####

``{r}
## tidyverse solution
iris %>% 
    filter(Species == "setosa") %>%
    select(Petal.Length) %>%
    summarise(mean = mean(Petal.Length))
``
    
```

````

will typeset to:

```{task}
Filter the `iris` data by `Species == "setosa"` and find the mean `Petal.Length`.
```

```{solution, multCode = T, titles = c("Base R", "tidyverse")}

``{r}
## base R solution
mean(iris$Petal.Length[
    iris$Species == "setosa"])
``

####

``{r}
## tidyverse solution
iris %>% 
    filter(Species == "setosa") %>%
    select(Petal.Length) %>%
    summarise(mean = mean(Petal.Length))
``
    
```

Note that there is also a `multCode` chunk that does not link to task and solution boxes e.g.

````

```{multCode}`r ''`

Two options: 

* Option 1

####

Two options:
    
* Option 2

```

````

will typeset to:

```{multCode}

Two options: 

* Option 1

####

Two options:
    
* Option 2

```

The `titles` option can be set as before.
